{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Notebook made by  \n",
    "\n",
    "|** Name** | **Student id** | **email**|\n",
    "|:- |:-|:-|\n",
    "|Dylan Wijman |10651012|dylanwijman@hotmail.com|\n",
    "|Eline Steensma|10589813|elinesteensma@gmail.com|\n",
    "|Sjoerd Paardekooper|10278397|sjoerd.paardekooper@gmail.com|\n",
    "\n",
    "### Pledge (taken from [Coursera's Honor Code](https://www.coursera.org/about/terms/honorcode) )\n",
    "\n",
    "\n",
    "Put here a selfie with your photo where you hold a signed paper with the following text: (if this is team work, put two selfies here). The link must be to some place on the web, not to a local file. \n",
    "\n",
    "> My answers to homework, quizzes and exams will be my own work (except for assignments that explicitly permit collaboration).\n",
    "\n",
    ">I will not make solutions to homework, quizzes or exams available to anyone else. This includes both solutions written by me, as well as any official solutions provided by the course staff.\n",
    "\n",
    ">I will not engage in any other activities that will dishonestly improve my results or dishonestly improve/hurt the results of others.\n",
    "\n",
    "<img src='https://github.com/dylanwijman/data-science/blob/master/pledge.jpg?raw=true'/>\n",
    "\n",
    "### Note\n",
    "* **Assignments without the selfies or completely filled in information will not be graded and receive 0 points.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Recap Exam\n",
    "\n",
    "This exam is meant to test how fluent or how rusty you are in Python. \n",
    "We do some simple things working with lists, counting things, and doing a bit of basic statistics.\n",
    "You may not remember everything at one. That is no problem, if you can reasonably fast find it back using Python's reference.\n",
    "\n",
    "Also, don't forget the great help that IPython can give you: TAB and ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start with running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'ASIAN', u'EXPORTERS', u'FEAR', u'DAMAGE', u'FROM']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re,pprint,nltk\n",
    "from __future__ import division\n",
    "from nltk.corpus import reuters \n",
    "# make a corpus of all words in the test files\n",
    "testIDs= [w for w in reuters.fileids() if w.startswith('test')]\n",
    "testWords=reuters.words(testIDs)\n",
    "testWords[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make the questions. \n",
    "Answer them  in the code block after the question. \n",
    "\n",
    "Reuse variables that you have defined in earlier questions in later questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "(1) How many words/tokens are there in testWords? And how many unique tokens/words? What is the average frequency of a word?\n",
    "Define a variable for each subquestion.\n",
    "Then print out all variables at once. Use this style for the other exercises as well.\n",
    "So something like:\n",
    "```\n",
    "NumWords = ...\n",
    "NumUnique = ...\n",
    "AvgFreq = ....\n",
    "NumWords, NumUnique, AvgFreq\n",
    "```\n",
    "Or even better with a nicely formatted string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  467205 words/tokens in testWords,  22337 unique words/tokens in testWords\n",
      "The average frequency of a word is 20.9161928639\n"
     ]
    }
   ],
   "source": [
    "NumWords = len(testWords)\n",
    "NumUnique = len(set(testWords))\n",
    "AvgFreq = NumWords / NumUnique\n",
    "\n",
    "print \"There are \", NumWords, \"words/tokens in testWords, \", NumUnique, \"unique words/tokens in testWords\"\n",
    "print \"The average frequency of a word is\", AvgFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(2) How many bigrams (a bigram is a sequence of two consequtive words)  are there in testWords? How many unique ones? What is the average bigram frequency? Explain the difference of the last two numbers with the numbers in the previous question. \n",
    "Make it easy for yourself. Just use the most \"dumb\" definition of bigram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "467205\n",
      "Totaal aantal bigrams = 467204\n",
      "Totaal Uniek aantal bigrams = 155763\n",
      "Gemiddelde bigram frequentie = 2.99945429916\n"
     ]
    }
   ],
   "source": [
    "from nltk import bigrams\n",
    "\n",
    "print len(testWords)\n",
    "# Converteer lijst met woorden naar lijst met bigrams\n",
    "testBigrams = list(bigrams(testWords))\n",
    "lenTestBigrams = len(testBigrams)\n",
    "uniLenTestBigrams = len(set(testBigrams))\n",
    "avgBigramFreq = lenTestBigrams / uniLenTestBigrams\n",
    "\n",
    "print \"Totaal aantal bigrams =\", lenTestBigrams\n",
    "print \"Totaal Uniek aantal bigrams =\", uniLenTestBigrams\n",
    "print \"Gemiddelde bigram frequentie =\", avgBigramFreq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(3)  There are quite some tokens in testWords which are not really \"words\".\n",
    "\n",
    "Use [regular expressions](https://docs.python.org/2/library/re.html) and use the list of english stopwords which can be obtained as follows:\n",
    "\n",
    "```\n",
    "from nltk.corpus import stopwords\n",
    "# test\n",
    "stopwords.words('english')[:20]\n",
    "```\n",
    "\n",
    "Don't display too many digits behind the comma: use the `round()` function to control that.\n",
    "\n",
    "3.1. Create the list of all \"punctuation tokens\" in testWords.\n",
    "\n",
    "3.2. Create the list of all \"stopword tokens\" in testWords. Use NLTK's english stopword list.\n",
    "\n",
    "3.3. Compute the percentage of all tokens in testWords that is a punctuation and the percentage of all tokens in testWords that is a stopword.\n",
    "\n",
    "3.4. How many (as a percentage) of the UNIQUE tokens in testWords is a punctuation? How many a stopword?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniquetokens: 17\n",
      "3.1 [u'.', u'.', u'.', u\"'\", u'-', u',', u'.', u'.', u'.', u'.', u'.', u'.', u'-', u',', u'-']\n",
      "3.2 [u'our', u'we', u'he', u'ours', u'he', u'we', u'he', u'he', u'his', u'we', u'he', u'we', u'he', u'he', u'we']\n",
      "3.3 Punctuationfrequentie on testwords: 0.142793848525\n",
      "3.3 StopwordFrequency on testwords: 0.00343746321208\n",
      "3.4 How many unique punctuation tokens are there in uniquetokens? 0.0761069078211 %\n",
      "3.4 How many unique stopwords are there in uniquetokens? 0.0716300308905 %\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from string import punctuation\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "pTestWords = [x for x in testWords if x in punctuation]\n",
    "englishStopwords = [x for x in testWords if x in stopwords.words('english')[:20]]\n",
    "pFreq = len(pTestWords) / len(testWords)\n",
    "sFreq = len(englishStopwords) / len(testWords)\n",
    "\n",
    "uniqueTokens = set(testWords)\n",
    "\n",
    "punctuationInUniqueTokens = [x for x in uniqueTokens if x in punctuation]\n",
    "stopwordsUniqueTokens = [x for x in uniqueTokens if x in englishStopwords]\n",
    "\n",
    "print \"Uniquetokens:\", len(punctuationInUniqueTokens)\n",
    "\n",
    "print \"3.1\", pTestWords[:15]\n",
    "print \"3.2\", englishStopwords[:15]\n",
    "print \"3.3 Punctuationfrequentie on testwords:\", pFreq\n",
    "print \"3.3 StopwordFrequency on testwords:\", sFreq\n",
    "print \"3.4 How many unique punctuation tokens are there in uniquetokens?\", (len(punctuationInUniqueTokens) / len(uniqueTokens)) * 100,\"%\"\n",
    "print \"3.4 How many unique stopwords are there in uniquetokens?\", (len(stopwordsUniqueTokens) / len(uniqueTokens)) * 100,\"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5 We will now start counting _how often_ words appear in the list `testWords`. Counting is a very important and often used tool. It is _expensive_ as it involves sorting.\n",
    "\n",
    "There are several ways to do counting, and we look at a few of them:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15048, 1, [u'the', u'the', u'the', u'the', u'the'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The number of times the word \"the\" occurs\n",
    "the = [x for x in testWords if x=='the']\n",
    "len(the), len(set(the)), the[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1 function calls in 0.000 seconds\n",
      "\n",
      "   Ordered by: standard name\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "exec: arg 1 must be a string, file, or code object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-29ce167c5ff4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtestWords\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'the'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mcProfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/cProfile.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(statement, filename, sort)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m             \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatement\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mSystemExit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/cProfile.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, cmd)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0mdict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__main__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrunctx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/cProfile.pyc\u001b[0m in \u001b[0;36mrunctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m             \u001b[0;32mexec\u001b[0m \u001b[0mcmd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglobals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocals\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: exec: arg 1 must be a string, file, or code object"
     ]
    }
   ],
   "source": [
    "\n",
    "# Each list has a count method, which is ideal for counting\n",
    "a = testWords.count('the')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Counter({'blue': 3, 'red': 2, 'yellow': 1}), 3)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This trick counts all items in one go and yields a dictionary\n",
    "from collections import Counter\n",
    "z = ['blue', 'red', 'blue', 'yellow', 'blue', 'red']\n",
    "Counter(z), Counter(z)['blue']\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'Durapipe', 1), (u'Irving', 17), (u'woods', 1), (u'hanging', 1), (u'HARDIE', 1)]\n"
     ]
    }
   ],
   "source": [
    "# with NLTK we can make a similar datastructure\n",
    "testfd= nltk.FreqDist(testWords)\n",
    "print testfd.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3.5.1 Use `set()` and dict comprehension to create a dict like `testfd` using the `.count()` method\n",
    "\n",
    "3.5.2 You now have 3 ways to make a wordcount dictionary. Use the timing functions to see which one is the fastest.\n",
    "\n",
    "3.5.3 Which percentage of the UNIQUE tokens in testWords is a hapax (i.e. occurs only once in testWords)?\n",
    "\n",
    "3.5.4 Which percentage of the   tokens in testWords is a hapax? \n",
    "\n",
    "3.5.5 Explain why the following test returns True: `len(testfd)==len(set(testWords))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#3.5.1.\n",
    "setTestwords = set(testWords)\n",
    "\n",
    "# Duurt op mijn PC te lang om te laden maar is volgens mij de goede code\n",
    "l = {x: testWords.count(x) for x in setTestwords}\n",
    "\n",
    "#3.5.2.\n",
    "cProfile.run(l)\n",
    "cProfile.run(Counter(setTestwords))\n",
    "cProfile.run(nltk.FreqDist(testWords))\n",
    "\n",
    "#3.5.3.\n",
    "hapax = [word for word, count in l if count == 1]\n",
    "print \"Percentage of unique tokens in testWords which is a hapax:\", (len(hapax) / len(setTestwords)) * 100,\"%\"\n",
    "\n",
    "#3.5.4.\n",
    "print \"Percentage of tokens in testWords which is a hapax:\", (len(hapax) / len(testwords)) * 100,\"%\"\n",
    "\n",
    "#3.5.5.\n",
    "Because the elements in the list are tuples which each represent a individual word. The amount/len of individual words is the same \n",
    "as the amount of inique words in a set. Since both represent the word and not the count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(4) Count the tokens in testWords. Make an estimate of the following probability: given a string t, if we draw an arbitrary  token from testWords, what is the chance that it equals t?\n",
    "\n",
    "Program it as a function prob(str).\n",
    "Give an example of a high and of a low probability word.\n",
    "\n",
    "Does prob work on every input string?\n",
    "\n",
    "Test that 'the probabilities add up to 1'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(5) Suppose we have printed out testWords  using exactly one space between each two tokens. Suppose we have covered a wall with this string. Now you throw a dart missile on this wall. Assume that it always hits exactly one character, which is either a space (inserted by our printing process) or a character in a token.\n",
    "\n",
    "5.1 What is the probability that it hits a space?\n",
    "\n",
    "5.2 Define a function prob(n) which for integer n returns the probability that the missile hits a token of length n.\n",
    "\n",
    "5.3 Nicely print out a table of the form \"n,  prob(n)\" which for each n returns   prob(n). Format it well, and truncate numbers. Bonus points for those who make a plot.\n",
    "\n",
    "5.3.1 Write a good test which indicates that prob(n) works correctly.\n",
    "\n",
    "5.4 What is the probability that it hits a stopword?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#5.1\n",
    "#Alle woorden achter elkaar plakken als string met een spatie ertussen -> totaal aantal spaties in de string / totaal aantal tekens\n",
    "\n",
    "#5.2\n",
    "def prob(n):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BONUS (if you have time left or got bored)\n",
    "\n",
    "Show that the  words in testWords have a Zipfian distribution. Count the words, order them by their frequency. Plot the log(frequency) times log(index of the word). \n",
    "\n",
    "Use `% matplotlib inline` to display the figure in the notebook.\n",
    "\n",
    "Is it a straight line?\n",
    "\n",
    "Now do the same for the unigrams and the bigrams together in one list. Is the plot \"better\"? What does 'better' mean here?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
